{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LightFM: A hybrid recommender engine library</h2>\n",
    "\n",
    "Getting to understand the underlying data representation:\n",
    "\n",
    "Datatype docs:<br>\n",
    "<a href=\"https://docs.python.org/3/tutorial/datastructures.html#dictionaries\">dictionaries</a><br>\n",
    "<a href=\"https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.ndarray.html\">numpy.ndarray</a><br>\n",
    "<a href=\"https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html\">scipy.sparse.csr.csr_matrix</a><br>\n",
    "<a href=\"https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.sparse.coo_matrix.html\">scipy.sparse.coo.coo_matrix</a><br>\n",
    "<a href=\"http://www.scipy-lectures.org/advanced/scipy_sparse/index.html\">scipy sparse datatypes tutorial</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "item_feature_labels <class 'numpy.ndarray'> (1682,)\n",
      "item_features <class 'scipy.sparse.csr.csr_matrix'> (1682, 1682)\n",
      "test <class 'scipy.sparse.coo.coo_matrix'> (943, 1682)\n",
      "train <class 'scipy.sparse.coo.coo_matrix'> (943, 1682)\n",
      "item_labels <class 'numpy.ndarray'> (1682,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "#fetch data with a threshold\n",
    "user_item_rating_data = fetch_movielens()\n",
    "print(type(user_item_rating_data))\n",
    "\n",
    "for key, value in user_item_rating_data.items():\n",
    "    print(key,type(value),value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions available:\n",
    "<br>\n",
    "<ul><li>BPR: Bayesian Personalised Ranking [1] pairwise loss. Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.</li><li>\n",
    "WARP: Weighted Approximate-Rank Pairwise [2] loss. Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired.</li>\n",
    "\n",
    "This example shows how to estimate these models on the Movielens dataset.\n",
    "\n",
    "[1] Rendle, Steffen, et al. \"BPR: Bayesian personalized ranking from implicit feedback.\" Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, 2009.\n",
    "\n",
    "[2] Weston, Jason, Samy Bengio, and Nicolas Usunier. \"Wsabie: Scaling up to large vocabulary image annotation.\" IJCAI. Vol. 11. 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print(repr(user_item_rating_data['item_feature_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print(repr(user_item_rating_data['item_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(repr(user_item_rating_data['item_features'].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 5469 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "#print training and testing data\n",
    "print(repr(user_item_rating_data['train']))\n",
    "print(repr(user_item_rating_data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Known Positives:\n",
      "          Seven (Se7en) (1995)\n",
      "          Indiana Jones and the Last Crusade (1989)\n",
      "          Contact (1997)\n",
      "     Recommended:\n",
      "          Scream (1996)\n",
      "          Contact (1997)\n",
      "          Air Force One (1997)\n",
      "User 25\n",
      "     Known Positives:\n",
      "          Toy Story (1995)\n",
      "          Twelve Monkeys (1995)\n",
      "          Dead Man Walking (1995)\n",
      "     Recommended:\n",
      "          Scream (1996)\n",
      "          Toy Story (1995)\n",
      "          Contact (1997)\n",
      "User 450\n",
      "     Known Positives:\n",
      "          Kolya (1996)\n",
      "          Devil's Own, The (1997)\n",
      "          Contact (1997)\n",
      "     Recommended:\n",
      "          Lost Highway (1997)\n",
      "          Devil's Advocate, The (1997)\n",
      "          Spawn (1997)\n"
     ]
    }
   ],
   "source": [
    "#create model using loss function of choice:\n",
    "#weighted approximate-rank pairwise, \n",
    "#uses gradiant descent, \n",
    "#uses users past rating history and neighborhood ratings\n",
    "model = LightFM(learning_rate=0.05, loss='warp')#also avaiable 'bpr'\n",
    "\n",
    "#train model\n",
    "model.fit(user_item_rating_data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "def recommend(model, data, uids):\n",
    "    \n",
    "    #number of users and movies in training data\n",
    "    n_users, n_items = data['train'].shape\n",
    "    \n",
    "    #generate recommendations for each user we input\n",
    "    for uid in uids:\n",
    "        \n",
    "        #movies they already like\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[uid].indices]\n",
    "        \n",
    "        #movies our model predicts they will like\n",
    "        scores = model.predict(uid, np.arange(n_items))\n",
    "        \n",
    "        #rank them in order of most liked to least liked\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        #print out the results\n",
    "        print(\"User %s\" % uid)\n",
    "        print(\"     Known Positives:\")\n",
    "        \n",
    "        for kp in known_positives[:3]:\n",
    "            print(\"          %s\" % kp)\n",
    "        \n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for ti in top_items[:3]:\n",
    "            print(\"          %s\" % ti)\n",
    "            \n",
    "    return\n",
    "\n",
    "recommend(model, user_item_rating_data, [3,25,450])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluating performance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.64, test 0.11.\n",
      "AUC: train 0.95, test 0.91.\n"
     ]
    }
   ],
   "source": [
    "#tracking the precision\n",
    "train_precision = precision_at_k(model, user_item_rating_data['train'], k=10).mean()\n",
    "test_precision = precision_at_k(model, user_item_rating_data['test'], k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, user_item_rating_data['train']).mean()\n",
    "test_auc = auc_score(model, user_item_rating_data['test']).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Working with features</h1>\n",
    "\n",
    "A true hybrid is the one where you also include the features of items and users instead of just the neighborhood similarity or latent factors. The next example deals with stack exchange data which is openly available on stackexchange archives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3221 users and 72360 items, with 4307 interactions in the test and 57830 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "from lightfm.datasets import fetch_stackexchange\n",
    "\n",
    "stkex_data = fetch_stackexchange('crossvalidated',\n",
    "                           test_set_fraction=0.1,\n",
    "                           indicator_features=False,\n",
    "                           tag_features=True)\n",
    "\n",
    "train = stkex_data['train']\n",
    "test = stkex_data['test']\n",
    "\n",
    "print('The dataset has %s users and %s items, '\n",
    "      'with %s interactions in the test and %s interactions in the training set.'\n",
    "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pure Collaborative filtering approach.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 448 ms, sys: 28 ms, total: 476 ms\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "# Set the number of threads; you can increase this\n",
    "# ify you have more physical cores available.\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 30\n",
    "NUM_EPOCHS = 3\n",
    "ITEM_ALPHA = 1e-6\n",
    "#lyst.github.io/lighfm/docs/lightfm.html\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "stkex_cf_model = LightFM(loss='warp', item_alpha=ITEM_ALPHA, no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time stkex_cf_model = stkex_cf_model.fit(train, epochs=NUM_EPOCHS, num_threads=NUM_THREADS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering train AUC: 0.888174\n",
      "Collaborative filtering test AUC: 0.345964\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(stkex_cf_model, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "test_auc = auc_score(stkex_cf_model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above the test AUC is < 0.5 which means this model is worse than chance. The biases are causing part of this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering test AUC: 0.501792\n",
      "<3221x72360 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 57830 stored elements in COOrdinate format>\n",
      "<3221x72360 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 4307 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "# Set biases to zero\n",
    "stkex_cf_model.item_biases *= 0.0\n",
    "\n",
    "test_auc = auc_score(stkex_cf_model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)\n",
    "print(repr(train))\n",
    "print(repr(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Let's incorporate some features</h2><br>This is where things start to get really interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1246 distinct tags, with values like ['bayesian', 'prior', 'elicitation'].\n"
     ]
    }
   ],
   "source": [
    "item_features = stkex_data['item_features']\n",
    "tag_labels = stkex_data['item_feature_labels']\n",
    "\n",
    "print('There are %s distinct tags, with values like %s.' % (item_features.shape[1], tag_labels[:3].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new model instance\n",
    "stkex_hyb_model = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "                no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Fit the hybrid model. Note that this time, we pass\n",
    "# in the item features matrix.\n",
    "stkex_hyb_model = stkex_hyb_model.fit(train,\n",
    "                item_features=item_features,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                num_threads=NUM_THREADS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid training set AUC: 0.856972\n"
     ]
    }
   ],
   "source": [
    "# Don't forget the pass in the item features again!\n",
    "train_auc = auc_score(stkex_hyb_model,\n",
    "                      train,\n",
    "                      item_features=item_features,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid training set AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid test set AUC: 0.708887\n"
     ]
    }
   ],
   "source": [
    "test_auc = auc_score(stkex_hyb_model,\n",
    "                    test,\n",
    "                    train_interactions=train,\n",
    "                    item_features=item_features,\n",
    "                    num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Byproduct</h2>\n",
    "Word2Vec like tag similarity via item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar tags for events: ['ancillary-statistics' 'box-muller' 'bimodal']\n",
      "Most similar tags for prior: ['mcmc' 'bayesian' 'range']\n",
      "Most similar tags for elicitation: ['t-distribution' 'plyr' 'rule-of-thumb']\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tags(model, tag_id):\n",
    "    # Define similarity as the cosine of the angle\n",
    "    # between the tag latent vectors\n",
    "    \n",
    "    # Normalize the vectors to unit length\n",
    "    tag_embeddings = (model.item_embeddings.T\n",
    "                      / np.linalg.norm(model.item_embeddings, axis=1)).T\n",
    "    \n",
    "    query_embedding = tag_embeddings[tag_id]\n",
    "    similarity = np.dot(tag_embeddings, query_embedding)\n",
    "    most_similar = np.argsort(-similarity)[1:4]\n",
    "    \n",
    "    return most_similar\n",
    "\n",
    "\n",
    "for tag in (u'events', u'prior', u'elicitation'):\n",
    "    tag_id = tag_labels.tolist().index(tag)\n",
    "    print('Most similar tags for %s: %s' % (tag_labels[tag_id],\n",
    "                                            tag_labels[get_similar_tags(stkex_hyb_model, tag_id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
